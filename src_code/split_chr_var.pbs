#!/bin/bash
#PBS -N chr_split
#PBS -j oe
#PBS -l select=1:ncpus=3:mem=32gb -l place=free
#PBS -m abe
#PBS -M phillevn@gmail.com


# We suppose that the genotype data vcf is stored in the directory /ds/home/r1952/TOPMED_GWAS/AA/ for African American and /ds/home/r1952/TOPMED_GWAS/EA/ for European Amerfican
# and the file names in the format chr${i}.dose.vcf.gz

# We want to store the filtered data in the directory /ddn/home2/r2725/projects/jeannette/data/ for each chromosome with directory name chr${i}_data and file name subset_chro${i}_AA.vcf.gz for AA and subset_chro${i}_EA.vcf.gz for EA

# Plink2 is used for filtered data with maf and max-maf since it is faster than Plink1.9, however, we must use Plink1.9 for fgwas function program

# Since our sample for AA is around 3000, we split the whole set of snps into smaller set  of size 1,000,000 and since sample size for EA  is around 10,000 we split the whole snps into subsets with  500,000 snps each for faster parallel submittion jobs

# You may need to make index file of vcf.gz file first if you have not done so, or you just un comment the 3rd code line below to make the index by using tablix program

cd ${PBS_O_WORKDIR}

outDIR="/ddn/home2/r2725/projects/jeannette/data/"
AA_id_path="/ddn/home2/r2725/projects/jeannette/data/AA_gwas_id.txt"
EA_id_path="/ddn/home2/r2725/projects/jeannette/data/EA_gwas_id.txt"
vcf_gz_DIR="/ds/home/r1952/TOPMED_GWAS/AA/"
plink2_path="/ddn/home2/r2725/apps/plink/plink2.0/plink2"

module load gcc/9.2.0

# /ddn/home2/r2725/apps/htslib-1.12/bin/tabix -p vcf /ddn/home2/r2725/projects/jeannette/data/chr1.dose.vcf.gz

for i in {20..20}; do

	cd ${outDIR}

	mkdir chr${i}_data

	cd chr${i}_data

	mkdir subset_chro${i}_AA_filtered

	mkdir subset_chro${i}_EA_filtered


	# subset the chromosome with the same topid from selected phenotype
	bcftools view -Oz -S ${AA_id_path} ${vcf_gz_DIR}chr${i}.dose.vcf.gz -o ${outDIR}chr${i}_data/subset_chro${i}_AA.vcf.gz
	# for EA 
	bcftools view -Oz -S ${EA_id_path} ${vcf_gz_DIR}chr${i}.dose.vcf.gz -o ${outDIR}chr${i}_data/subset_chro${i}_EA.vcf.gz

	# run Plink2 to converse vcf to filter maf >0.01 and < 0.999 file 

	${plink2_path} --vcf ${outDIR}chr${i}_data/subset_chro${i}_AA.vcf.gz --maf 0.01 --max-maf 0.99 --max-alleles 2 --min-alleles 2 --id-delim  --recode vcf --out ${outDIR}chr${i}_data/subset_chro${i}_AA_filtered

	${plink2_path} --vcf ${outDIR}chr${i}_data/subset_chro${i}_EA.vcf.gz --maf 0.01 --max-maf 0.99 --max-alleles 2 --min-alleles 2 --id-delim  --recode vcf --out ${outDIR}chr${i}_data/subset_chro${i}_EA_filtered


	# Split the chromosome into smaller files with 1,000,000 snps and below
	#grab the header
	head -n 100 subset_chro${i}_AA_filtered.vcf | grep "^#" >header
	#grab the non header lines
	grep -v "^#" subset_chro${i}_AA_filtered.vcf >variants
	#split into chunks with 1000 lines
	split -l 1000000 variants subset_chro${i}_AA_filtered_split
	#reattach the header to each and clean up

	for j in subset_chro${i}_AA_filtered_split*;
		do cat header $j >$j.vcf && gzip -k $j.vcf  && rm -f $j &&
			plink2_path --vcf ${j}.vcf.gz --id-delim --make-bed --out ${outDIR}chr${i}_data/${j}_bed;
		done
	rm -f header variants

#	mkdir subset_chro${i}_AA_filtered_split # dont't need

	mv subset_chro${i}_AA_filtered_split* ./subset_chro${i}_AA_filtered/

	# going to EA diretory

#	cd ../subset_chro${i}_EA_filtered

	# Split the chromosome into smaller files with 1,000,000 snps and below
	#grab the header
	head -n 100 subset_chro${i}_EA_filtered.vcf | grep "^#" >header
	#grab the non header lines
	grep -v "^#" subset_chro${i}_EA_filtered.vcf >variants
	#split into chunks with 1000 lines
	split -l 500000 variants subset_chro${i}_EA_filtered_split
	#reattach the header to each and clean up
	for j in subset_chro${i}_EA_filtered_split*;
		do cat header $j >$j.vcf && gzip -k $j.vcf &&  rm -f $j &&
			plink2_path --vcf ${j}.vcf.gz --id-delim --make-bed --out ${outDIR}chr${i}_data/${j}_bed;
		done
	rm -f header variants


	mv subset_chro${i}_EA_filtered_split* ./subset_chro${i}_EA_filtered/;
done

